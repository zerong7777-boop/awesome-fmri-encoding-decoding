# Awesome fMRI Decoding (Categorized)

A curated list of **fMRI-based brain decoding** papers, datasets and code, focusing on **reconstructing images / videos / language / audio from brain activity**.

If you find this repo helpful, please give it a â­ and consider contributing new papers via pull requests.

---

## Contents

1. [Survey & Overview](#survey--overview)
2. [Datasets & Benchmarks](#datasets--benchmarks)
3. [Language & Narrative Decoding (Brain â†’ Text)](#language--narrative-decoding-brain--text)
4. [Visual Image Reconstruction (Brain â†’ Image)](#visual-image-reconstruction-brain--image)
   - [Early & Pre-generative Works](#early--pre-generative-works)
   - [GAN / VAEâ€“based](#gan--vae-based)
   - [Diffusion-based](#diffusion-based)
   - [Cross-Subject & Mixture-of-Experts](#cross-subject--mixture-of-experts)
5. [Video & Dynamic Scene Decoding](#video--dynamic-scene-decoding)
6. [Visual-to-fMRI Encoding & Data Augmentation](#visual-to-fmri-encoding--data-augmentation)
7. [Audio & Music Decoding](#audio--music-decoding)
8. [Multimodal & Foundation-Model-based Decoding](#multimodal--foundation-model-based-decoding)
9. [Clinical / Cognitive & Mental-State Decoding](#clinical--cognitive--mental-state-decoding)
10. [Toolboxes, Tutorials & Awesome Lists](#toolboxes-tutorials--awesome-lists)
11. [Contributing](#contributing)

---

## Survey & Overview

**A Survey on fMRI-based Brain Decoding for Reconstructing Multimodal Stimuli** (arXiv 2025) â€“ Recent survey of fMRI-based decoding for images, text, audio and video, with taxonomy of tasks and models.  [ğŸ“„ Paper](https://arxiv.org/abs/2503.15978)  â€¢  [ğŸ’» Project Code](https://github.com/LpyNow/BrainDecodingImage)

**Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy** (IEEE TAI 2025) â€“ Survey of brain-conditional generative models (image, audio, text) with taxonomy and evaluation protocols.  [ğŸ“„ Paper](https://www.computer.org/csdl/journal/ai/2025/05/10798967/22EatqRGQxO)

**Deep Generative Models in Brain Encoding and Decoding** (Engineering 2019) â€“ Early review of using deep generative models for brain encoding/decoding.  [ğŸ“„ Paper](https://doi.org/10.1016/j.eng.2019.03.011)

---

## Datasets & Benchmarks

**Natural Scenes Dataset (NSD)** â€“ High-resolution 7T fMRI while subjects view thousands of natural images; widely used for visual reconstruction.  [ğŸŒ Website](https://naturalscenesdataset.org/)  â€¢  [ğŸ“‚ Data](https://osf.io/9pjky/)

**Deep Image Reconstruction (DIR) dataset** â€“ fMRI data for the Kamitani *Deep Image Reconstruction* study.  [ğŸ“‚ Data](https://openneuro.org/datasets/ds001506)

**Narratives / Story Listening datasets** â€“ Long-form spoken story comprehension, used for fMRI-to-text decoding.  [ğŸŒ Narratives Lab](https://www.narrativeslab.org/)  â€¢  [ğŸ“‚ Data](https://openneuro.org/datasets/ds002345)

**Semantic reconstruction of continuous language â€“ dataset** â€“ Data accompanying Tang et al., Nat Neurosci 2023.  [ğŸ“‚ Data](https://openneuro.org/datasets/ds003020)


---

## Language & Narrative Decoding (Brain â†’ Text)

**Semantic Reconstruction of Continuous Language from Non-invasive Brain Recordings** (Nat Neurosci 2023) â€“ fMRI-to-text decoder that reconstructs continuous language from cortical semantic representations.  [ğŸ“„ Paper](https://www.nature.com/articles/s41593-023-01304-9)  â€¢  [ğŸ’» Code](https://github.com/HuthLab/semantic-decoding)  â€¢  [ğŸ“‚ Dataset](https://openneuro.org/datasets/ds003020)

**UniCoRN: Unified Cognitive Signal ReconstructioN Bridging Cognitive Signals and Human Language** (ACL 2023) â€“ Proposes the fMRI2text task and a unified encoder for fMRI/EEG with a pretrained language model decoder.  [ğŸ“„ Paper](https://arxiv.org/abs/2307.05355)  â€¢  [ğŸ’» Code](https://github.com/DUTIR-ESLab/UniCoRN)

**Brain-Inspired fMRI-to-Text Decoding via Incremental and Wrap-Up Language Modeling (CogReader)** (NeurIPS 2025 Spotlight) â€“ NeurIPS 2025 work that mimics human segmented language comprehension; decodes long narratives with segment-wise incremental decoding and wrap-up integration.  [ğŸ“„ Paper](https://openreview.net/forum?id=REIo9ZLSYo)  â€¢  [ğŸ’» Code](https://github.com/WENXUYUN/CogReader)


---

## Visual Image Reconstruction (Brain â†’ Image)

### Early & Pre-generative Works

**Reconstructing Natural Scenes from fMRI Patterns Using Hierarchical Visual Features** (NeuroImage 2011) â€“ Uses Gabor and Gist-like features plus Bayesian decoding to reconstruct natural images from early visual cortex.  [ğŸ“„ Paper](https://doi.org/10.1016/j.neuroimage.2010.07.063)

**Visual Experience Reconstruction from Movie fMRI** (Current Biology 2011) â€“ Classic work reconstructing low-resolution movies from fMRI responses during movie watching.  [ğŸ“„ Paper](https://doi.org/10.1016/j.cub.2011.01.031)

### GAN / VAEâ€“based

**Deep Image Reconstruction from Human Brain Activity** (PLoS Comput Biol 2019) â€“ Maps fMRI to DNN feature space and reconstructs images via a deep generative model.  [ğŸ“„ Paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006633)  â€¢  [ğŸ’» Code](https://github.com/KamitaniLab/DeepImageReconstruction)  â€¢  [ğŸ“‚ Dataset](https://openneuro.org/datasets/ds001506)

**From Voxels to Pixels and Back: Self-supervision in Natural-Image Reconstruction from fMRI** (NeurIPS 2019) â€“ Self-supervised framework aligning fMRI with deep visual features for image reconstruction.  [ğŸ“„ Paper](https://arxiv.org/abs/1907.02431)  â€¢  [ğŸ’» Code](https://github.com/WeizmannVision/ssfmri2im)

**Reconstructing Natural Scenes from fMRI Patterns Using BigBiGAN** (preprint) â€“ Uses BigBiGAN latent space for fMRI-to-image reconstruction.  [ğŸ“„ Paper](https://arxiv.org/abs/2011.12243)

### Diffusion-based

**Brain-Diffuser: Natural Scene Reconstruction from fMRI Signals Using Generative Latent Diffusion** (Sci Rep 2023) â€“ Conditions latent diffusion on fMRI-aligned deep features to reconstruct images on NSD.  [ğŸ“„ Paper](https://www.nature.com/articles/s41598-023-42891-8)  â€¢  [ğŸ’» Code](https://github.com/ozcelikfu/brain-diffuser)  â€¢  [ğŸ“‚ Dataset: NSD](https://naturalscenesdataset.org/)

**Reconstructing the Mindâ€™s Eye: fMRI-to-Image with Contrastive Learning and Diffusion Priors (MindEye)** (NeurIPS 2023) â€“ Contrastive fMRI-to-CLIP encoder plus diffusion prior for high-fidelity reconstructions.  [ğŸ“„ Paper](https://arxiv.org/abs/2305.18274)  â€¢  [ğŸŒ Project](https://medarc-ai.github.io/mindeye/)  â€¢  [ğŸ’» Code](https://github.com/MedARC-AI/fMRI-reconstruction-NSD)

**MindDiffuser: Controlled Image Reconstruction from Human Brain Activity with Semantic and Structural Diffusion** (ACM MM 2023) â€“ Two-stage semantic and structural diffusion with extra controllability.  [ğŸ“„ Paper](https://arxiv.org/abs/2308.04249)  â€¢  [ğŸ’» Code](https://github.com/YingxingLu/MindDiffuser)

**NeuralDiffuser: Neuroscience-Inspired Diffusion Guidance for fMRI Visual Reconstruction** (IEEE TIP 2025) â€“ Introduces neuroscience-inspired guidance signals to steer diffusion sampling using fMRI activity.  [ğŸ“„ Paper](https://arxiv.org/abs/2401.01713)  â€¢  [ğŸ’» Code](https://github.com/neu-diffusion/NeuralDiffuser)

**Mental Image Reconstruction from Human Brain Activity** (Neural Networks 2024) â€“ Uses diffusion priors with additional perceptual and semantic constraints for mental image reconstruction.  [ğŸ“„ Paper](https://www.sciencedirect.com/science/article/pii/S0893608023006470)

**Bridging Brains and Concepts: Interpretable Visual Decoding from fMRI with Semantic Bottlenecks** (NeurIPS 2025 Poster) â€“ Inserts an explicit semantic bottleneck into the fMRI-to-image pipeline for concept-level interpretability, building on diffusion-based visual decoders.  [ğŸ“„ Paper](https://openreview.net/forum?id=K6ijewH34E)  â€¢  [ğŸ“„ PDF](https://openreview.net/pdf/167d5c3c08cdd7367883eeec0b26002c059215f8.pdf)  â€¢  [ğŸŒ NeurIPS page](https://neurips.cc/virtual/2025/poster/118670)

### Cross-Subject & Mixture-of-Experts

**ZEBRA: Towards Zero-Shot Cross-Subject Generalization for Universal Brain Visual Decoding** (NeurIPS 2025 Poster) â€“ Disentangles subject-specific and semantic components of fMRI via adversarial training, enabling zero-shot cross-subject image reconstruction.  [ğŸ“„ Paper](https://arxiv.org/abs/2510.27128)  â€¢  [ğŸ“„ PDF](https://openreview.net/pdf/7a4f583ef54685490be5c58986a3ad803aac087c.pdf)  â€¢  [ğŸ’» Code](https://github.com/xmed-lab/ZEBRA)

**MoRE-Brain: Routed Mixture of Experts for Interpretable and Generalizable Cross-Subject fMRI Visual Decoding** (NeurIPS 2025 Poster) â€“ Routed mixture-of-experts mapping fMRI to CLIP space with subject-specific routers and diffusion decoder; emphasizes interpretability of expert routing.  [ğŸ“„ Paper](https://arxiv.org/abs/2505.15946)  â€¢  [ğŸŒ OpenReview](https://openreview.net/forum?id=fYSPRGmS6l)  â€¢  [ğŸ’» Code](https://github.com/yuxiangwei0808/MoRE-Brain)


---

## Video & Dynamic Scene Decoding

**Visual Experience Reconstruction from Movie fMRI** (Current Biology 2011) â€“ Reconstructs natural movies from early visual cortex responses.  [ğŸ“„ Paper](https://doi.org/10.1016/j.cub.2011.01.031)

**CLSR: Decoding Complex Video and Story Stimuli from fMRI** (Nat Neurosci 2023) â€“ Large-scale movie & story dataset with joint video / text decoding from fMRI.  [ğŸ“„ Paper](https://doi.org/10.1038/s41593-023-01327-2)


---

## Visual-to-fMRI Encoding & Data Augmentation

> These works learn **image â†’ fMRI** mappings (encoding) and often use them to synthesize fMRI for data augmentation or analysis, which can improve fMRI-to-image decoders.

**SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning** (NeurIPS 2025 Poster / arXiv 2025) â€“ Probabilistic visual-to-fMRI encoder with BrainVAE and semantic-to-neural mapper; synthesized fMRI improves downstream decoding.  [ğŸ“„ Paper](https://arxiv.org/abs/2508.10298)  â€¢  [ğŸ“„ PDF](https://openreview.net/pdf/3971b93a4f08a3549d29904c63d514e0df961001.pdf)


---

## Audio & Music Decoding


---

## Multimodal & Foundation-Model-based Decoding

**MindReader: Reconstructing Complex Images from Brain Activities** (NeurIPS 2022) â€“ Uses CLIP space and StyleGAN2 as generative prior for complex image reconstruction from fMRI.  [ğŸ“„ Paper](https://arxiv.org/abs/2209.12951)  â€¢  [ğŸ’» Code](https://github.com/yuvalsim/MindReader)

**UMBRAE: Unified Multimodal Brain Decoding** (ECCV 2024) â€“ Unified framework that decodes images and text from brain activity using multimodal foundation models.  [ğŸ“„ Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/01133.pdf)  â€¢  [ğŸŒ Project](https://weihaox.github.io/UMBRAE)

**Joint Modeling of fMRI and EEG Imaging Using Ordinary Differential Equation-based Hypergraph Neural Networks (FE-NET)** (NeurIPS 2025) â€“ Jointly models asynchronous fMRI-EEG data via GAN-based hypergraph generation and Neural ODEâ€“based temporal dynamics for multimodal brain decoding.  [ğŸ“„ Paper](https://openreview.net/pdf/053f8c5a43f7051852d82cdcb8ab742f69065ea2.pdf)


---

## Clinical / Cognitive & Mental-State Decoding


---

## Toolboxes, Tutorials & Awesome Lists

**DeepImageReconstruction** â€“ Official code for Kamitani *Deep Image Reconstruction*, including full pipeline from preprocessing to reconstruction.  [ğŸ’» Code](https://github.com/KamitaniLab/DeepImageReconstruction)

**semantic-decoding** â€“ Official HuthLab code for semantic reconstruction of continuous language from fMRI.  [ğŸ’» Code](https://github.com/HuthLab/semantic-decoding)

**MindReader (code)** â€“ Implementation of MindReader CLIP-based decoder with StyleGAN2 generator.  [ğŸ’» Code](https://github.com/yuvalsim/MindReader)

**awesome-brain-decoding** â€“ A broader awesome list covering EEG / fMRI / ECoG decoding.  [ğŸ“¦ GitHub](https://github.com/NeuSpeech/awesome-brain-decoding)

**Awesome Brain Encoding & Decoding** â€“ Another general collection of brain encoding / decoding papers.  [ğŸ“¦ GitHub](https://github.com/subbareddy248/Awesome-Brain-Encoding--Decoding)


---

## Contributing

Contributions are very welcome!  Before opening a PR:

1. Check that the work is **about fMRI-based brain decoding or closely related encoding / data-augmentation** (or has a strong fMRI component).
2. Choose the most appropriate category and sub-category.
3. Use the following format for each entry:

   ```markdown
   **Paper Title** (Conf./Journal Year) â€“ Short one-sentence description.  [ğŸ“„ Paper](...)  â€¢  [ğŸ’» Code](...)  â€¢  [ğŸ“‚ Dataset](...)
